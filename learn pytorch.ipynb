{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量/Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量类似于 NumPy 的 ndarrays，此外，张量还可以用于 GPU 来加速计算。  \n",
    "注：张量/tensor 可以简化理解为（多维）数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function #为了可以使用后续版本的特性\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 构造一个未初始化的 5*3 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.5873e-43, 3.6013e-43, 3.5873e-43],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.1704e-41, 0.0000e+00, 2.2369e+08],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3) #空矩阵不是零矩阵，所以输出不一定是全 0\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 构造一个随机初始化的 5*3 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9049, 0.9467, 0.5134],\n",
      "        [0.8048, 0.3236, 0.2807],\n",
      "        [0.9308, 0.8684, 0.8272],\n",
      "        [0.8675, 0.7621, 0.1665],\n",
      "        [0.4940, 0.9595, 0.6080]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 构造一个数据类型为 long 的 5*3 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype = torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 直接用数据构造张量（tensor）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 创建一个基于现有张量的张量，以下方法会重新使用原 tensor 的属性，如：dtype，除非用户提供新的数据（给这个新张量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.2098,  0.1333, -0.5087],\n",
      "        [-1.2647, -2.0367,  0.4985],\n",
      "        [ 0.8054, -1.3955,  0.4633],\n",
      "        [-0.2706, -0.0993,  0.0312],\n",
      "        [-0.3612,  1.7678,  2.1830]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype = torch.double)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype = torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 获取张量的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> torch.Size 是一个元组，因此支持所有元组的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 操作/Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加/add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. add：语法1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4288,  0.3394, -0.1859],\n",
      "        [-0.8656, -1.9145,  1.2214],\n",
      "        [ 1.2708, -1.2107,  1.3144],\n",
      "        [ 0.2383,  0.7128,  0.4918],\n",
      "        [-0.1900,  2.6460,  2.6500]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. add：语法2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4288,  0.3394, -0.1859],\n",
      "        [-0.8656, -1.9145,  1.2214],\n",
      "        [ 1.2708, -1.2107,  1.3144],\n",
      "        [ 0.2383,  0.7128,  0.4918],\n",
      "        [-0.1900,  2.6460,  2.6500]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. add：提供一个用于输出的张量作为参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4288,  0.3394, -0.1859],\n",
      "        [-0.8656, -1.9145,  1.2214],\n",
      "        [ 1.2708, -1.2107,  1.3144],\n",
      "        [ 0.2383,  0.7128,  0.4918],\n",
      "        [-0.1900,  2.6460,  2.6500]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. add：原地操作/in-place（不使用额外的变量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4288,  0.3394, -0.1859],\n",
      "        [-0.8656, -1.9145,  1.2214],\n",
      "        [ 1.2708, -1.2107,  1.3144],\n",
      "        [ 0.2383,  0.7128,  0.4918],\n",
      "        [-0.1900,  2.6460,  2.6500]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <span id='actions_'>任何**原地**改变张量的操作都带有后缀`_`，如`x.copy_(y)`，`x.t_()`，这会改变 x 原本的值。</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 可以使用标准的 NumPy 索引和其他的各种功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1333, -2.0367, -1.3955, -0.0993,  1.7678])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])\n",
    "#输出 x 的第 1 列（从 0 开始）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改变尺寸/resize/reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 如果需要改变张量的尺寸，可以使用 `torch.view`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)              #randn 随机的正态分布\n",
    "y = x.view(16)                     #非 16 会 invalid\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 如果你有一个 1 元素的张量，通过 `.item()` 可以获取到元素的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1328])\n",
      "1.1328086853027344\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())    #只有一个元素的张量才可以用.item，返回值是一个 number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更多 tensor 的操作，包括置换、索引、切片、数学运算、线性代数、随机数等等，可以参考[文档](https://pytorch.org/docs/torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 与 NumPy 的互动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch 的张量和 NumPy 的数组将共享它们的内存地址(如果 Torch 张量存在于 CPU 上) ，更改其中一个将另一个也会改变。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将 Torch 张量转换为 NumPy 数组：Tensor → Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看 numpy 数组的值是如何改变的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1) \n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `add_` 为什么有 `_` 参考[这里](#actions_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将 NumPy 数组转换为 Torch 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out = a)    #如果 out = b 会报错：返回值必须是（numpy 的）ArrayType\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有 CPU 上的张量，除了 CharTensor，都支持与 NumPy 互相转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA 张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量可通过 `.to` 转移到任何设备上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅在有 CUDA 设备时可运行\n",
    "# 通过 torch.device 对象将张量放入/移出 GPU\n",
    "x = torch.randn(5, 3)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # 一个 CUDA 设备的对象\n",
    "    y = torch.ones_like(x, device=device)  # 直接在 GPU 上新建一个张量\n",
    "    x = x.to(device)                       # 或者通过'to(\"cuda\")'转移到 GPU 上\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # '.to' 可以同时修改 dtype!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # AUTOGRAD：自动微分/AUTOMATIC DIFFERENTIATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 的核心就是 `autograd` 包，它可以为张量的所有操作自动求微分。他是一个“由运行定义”的框架——你可以用代码指定如何反向传播，每一次迭代都可以不一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量/Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Tensor` 是这个包的最重要的类。如果你把张量的 `.requires_grad` 属性置为 `True`，它会追踪张量上的所有操作。结束计算时，调用 `.backward()` 可以自动计算当前张量的所有梯度并自动累加在 `.grad` 属性上。  \n",
    "  \n",
    "若要停止追踪一个张量，你可以调用 `.detach()` 来把当前张量从计算历史中剥离，这样后续的张量计算就不会被追踪。  \n",
    "  \n",
    "为了避免继续追踪张量的计算以及内存占用，你可以用 `with torch.no_grad():` 来包裹代码块。这样操作在评估模型时很有用，因为模型在 `requires)grad=True` 时，参数可以被训练；但是评估模型时并不需要梯度（来训练模型）。  \n",
    "  \n",
    "还有一个在自动计算梯度是很重要的类：`Function`  \n",
    "  \n",
    "`Tensor` 和 `Function` 相互配合建立起一个无环图，这个无环图包含了所有计算的历史记录。每个张量都有一个 `.grad_fn` 属性，这个属性是创建这个 `Tensor` 的 `Function` 类的引用。（除了那些用户设定 `grad_fn is None` 的张量）  \n",
    "  \n",
    "如果你要计算导数，你可以调用 `Tensor` 的 `.backward()`。如果 `Tensor` 是一个标量（比如只有一个元素的张量），不需要为 `backward()` 指定任何参数，一旦这个张量有不止一个元素， 你就需要指定一个跟张量维度匹配的 `gradient` 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度/Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
